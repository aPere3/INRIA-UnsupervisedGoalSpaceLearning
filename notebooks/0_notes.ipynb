{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation learning\n",
    "\n",
    "We use this notebook as notes for reflections on the project\n",
    "\n",
    "### What is the goal of our work? \n",
    "\n",
    ">The goal of our work is to propose a method that allows to learn a representation to use with goal exploration models.\n",
    "\n",
    "In our setup, we will work on a static visual scene with moving objects. The point of our work is to learn a representation that use raw images, and that allows the exploration algorithms to perform with images as they do with engineered features. The basic idea of exploration algorithms is to generate goals in the sensorimotor space. Depending on the algorithm, a different assembly of the following strategies is used:\n",
    "+ Generate a random goal in the sensorimotor space\n",
    "+ Generate a goal close to an already explored goal\n",
    "+ Generate goals that lies outside of the convex hull of known goals\n",
    "\n",
    "In the ideal case, our representation would comply with those needs of the exploration, and:\n",
    "+ Provide physical consistence: a random point of the representation should be physically plausible\n",
    "+ Linearize around known points: a point close to an already known point should be plausible as well and not that far from the known point.\n",
    "+ Extrapolate to points unseen during training (out of convex hull)\n",
    "\n",
    "This actually boils down to well known machine learning problems such as:\n",
    "+ Manifold Learning\n",
    "+ Representation Learning\n",
    "\n",
    "Multiple algorithms exists to tackle this problem, for example:\n",
    "+ PCA\n",
    "+ Autoencoders\n",
    "+ Kernel PCA\n",
    "+ Isomap\n",
    "+ LLE\n",
    "+ T-SNE\n",
    "\n",
    "Lately, neural networks have shown the best performances on this topic, which is why we will mainly experiments on those techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders\n",
    "\n",
    "Autoencoder is the main neural-network based way to learn a low dimensional representation. The principle is really simple for one accustomed to neural network: A simple feedforward network (minimal 1 layer setup) os trained to copy input to output. It is hence unsupervised. The basic setup contains less hidden units than inputs and outputs. Thus, the network must learn to model what is static and what is changing in the data to rewrite the output. \n",
    "\n",
    "In __Sparse__ autoencoders, a code sparsity penalty is added to the objective function to minimize. \n",
    "\n",
    "In __Contractive__ autoencoders, a derivative based penalty is added to the objective function to enforce "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "\n",
    "+ Use first derivative constraint on optimization for autoencoder to favor local linearity\n",
    "+ Use segmentation in some way...\n",
    "+ Train an autoencoder and check if out of manifold samples are in or out of the  convex polytope of train samples (http://stackoverflow.com/questions/16750618/whats-an-efficient-way-to-find-if-a-point-lies-in-the-convex-hull-of-a-point-cl), and how is this code decoded by the decoder. \n",
    "+ Train an autoencoder with a derivative penalty on code for contiguous data. This is slow feature analysis.\n",
    "+ Train a GAN and use directions of improvement to generate goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read\n",
    "+ [ ] [A hybrid network: Scattering and ConvNet](https://openreview.net/pdf?id=ryPx38qge)\n",
    "+ [ ] [Understanding Deep Convolutional Networks](https://arxiv.org/pdf/1601.04920v1.pdf)\n",
    "+ [ ] [Understanding Deep features with Computer Generated imagery](http://imagine.enpc.fr/~aubrym/projects/features_analysis/texts/understanding_deep_features_with_CG.pdf)\n",
    "+ [ ] [Unsupervised representation learning with DCGANS](https://arxiv.org/pdf/1511.06434.pdf)\n",
    "+ [ ] [A guide to convolution arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "+ [ ] [InfoGan](https://arxiv.org/pdf/1606.03657.pdf)\n",
    "+ [ ] [Improved techniques for training Gans](https://arxiv.org/pdf/1606.03498.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
